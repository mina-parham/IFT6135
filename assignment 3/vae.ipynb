{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qC71Qv1-TtI-"
      },
      "source": [
        "\n",
        "Solution template for the question 1.6-1.7. This template consists of following steps. Except the step 2, you don't need to modify it to answer the questions.\n",
        "1.   Initialize libraries\n",
        "2.   **Insert the answers for the questions 1.1~1.5 in q1_solution (this is the part you need to fill)**\n",
        "3.   Define data loaders\n",
        "4.   Define VAE network architecture\n",
        "5.   Initialize the model and optimizer\n",
        "6.   Train the model\n",
        "7.   Save the model\n",
        "8.   Load the model\n",
        "9.   Evaluate the model with importance sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mcs7QFvETxQJ"
      },
      "source": [
        "Initialize libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uLoP5GRpEPbI"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NTB40neeR6-k"
      },
      "source": [
        "Complete **functions in q1_solution** to answer the questions 1.1~1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0Kr08AArNlHU"
      },
      "outputs": [],
      "source": [
        "from q1_solution import log_likelihood_bernoulli, log_likelihood_normal, log_mean_exp, kl_gaussian_gaussian_analytic, kl_gaussian_gaussian_mc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r3v_ld3ITRFl"
      },
      "source": [
        "Define data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oiK4L0TdETNb"
      },
      "outputs": [],
      "source": [
        "def get_data_loader(dataset_location, batch_size):\n",
        "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
        "    # start processing\n",
        "    def lines_to_np_array(lines):\n",
        "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
        "    splitdata = []\n",
        "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
        "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
        "        filepath = os.path.join(dataset_location, filename)\n",
        "        utils.download_url(URL + filename, dataset_location)\n",
        "        with open(filepath) as f:\n",
        "            lines = f.readlines()\n",
        "        x = lines_to_np_array(lines).astype('float32')\n",
        "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
        "        # pytorch data loader\n",
        "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
        "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
        "        splitdata.append(dataset_loader)\n",
        "    return splitdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TZsL1gLLEVJM"
      },
      "outputs": [],
      "source": [
        "train, valid, test = get_data_loader(\"binarized_mnist\", 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8PoFxey7TUFS"
      },
      "source": [
        "Define VAE network architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "POBmU6UCEb4l"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(784, 300),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(300, 300),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(300, 2 * latent_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        z_mean, z_logvar = self.mlp(x.view(batch_size, 784)).chunk(2, dim=-1)\n",
        "        return z_mean, z_logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(latent_size, 300),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(300, 300),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(300, 784),\n",
        "        )\n",
        "        \n",
        "    def forward(self, z):\n",
        "        return self.mlp(z) - 5.\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_size):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encode = Encoder(latent_size)\n",
        "        self.decode = Decoder(latent_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z_mean, z_logvar = self.encode(x)\n",
        "        z_sample = z_mean + torch.exp(z_logvar / 2.) * torch.randn_like(z_logvar)\n",
        "        x_mean = self.decode(z_sample)\n",
        "        return z_mean, z_logvar, x_mean\n",
        "\n",
        "    def loss(self, x, z_mean, z_logvar, x_mean):\n",
        "        ZERO = torch.zeros(z_mean.size())\n",
        "        #kl = kl_gaussian_gaussian_mc(z_mean, z_logvar, ZERO, ZERO, num_samples=1000).mean()\n",
        "        kl = kl_gaussian_gaussian_analytic(z_mean, z_logvar, ZERO, ZERO).mean()\n",
        "        recon_loss = -log_likelihood_bernoulli(\n",
        "            torch.sigmoid(x_mean.view(x.size(0), -1)),\n",
        "            x.view(x.size(0), -1),            \n",
        "        ).mean()\n",
        "        return recon_loss + kl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Phg07ERvTYuh"
      },
      "source": [
        "Initialize a model and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "colab_type": "code",
        "id": "xTxgDwZfEesO",
        "outputId": "4d0db765-9306-4b84-e66b-fe8403567623"
      },
      "outputs": [],
      "source": [
        "vae = VAE(100)\n",
        "params = vae.parameters()\n",
        "optimizer = Adam(params, lr=3e-4)\n",
        "print(vae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oqw9SI7aTdtG"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SWtQakAOEhxN"
      },
      "outputs": [],
      "source": [
        "for i in range(20):\n",
        "    # train\n",
        "    for x in train:\n",
        "        optimizer.zero_grad()\n",
        "        z_mean, z_logvar, x_mean = vae(x)\n",
        "        loss = vae.loss(x, z_mean, z_logvar, x_mean)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # evaluate ELBO on the valid dataset\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0.\n",
        "        total_count = 0\n",
        "        for x in valid:\n",
        "            total_loss += vae.loss(x, *vae(x)) * x.size(0)\n",
        "            total_count += x.size(0)\n",
        "        print('-elbo: ', (total_loss / total_count).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HXp5vuhDTg1J"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JYfmW5TAElEO"
      },
      "outputs": [],
      "source": [
        "torch.save(vae, 'model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Iz6QX_KTizK"
      },
      "source": [
        "Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Hqcb8BrmEnMh"
      },
      "outputs": [],
      "source": [
        "vae = torch.load('model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OTpoVRncTmSR"
      },
      "source": [
        "Evaluate the $\\log p_\\theta(x)$ of the model on test by using importance sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tc2q6dxgEsIh"
      },
      "outputs": [],
      "source": [
        "total_loss = 0.\n",
        "total_count = 0\n",
        "with torch.no_grad():\n",
        "    #x = next(iter(test))\n",
        "    for x in test:\n",
        "        # init\n",
        "        K = 200\n",
        "        M = x.size(0)\n",
        "\n",
        "        # Sample from the posterior\n",
        "        z_mean, z_logvar = vae.encode(x)\n",
        "        eps = torch.randn(z_mean.size(0), K, z_mean.size(1))\n",
        "        z_samples = z_mean[:, None, :] + torch.exp(z_logvar / 2.)[:, None, :] * eps # Broadcast the noise over the mean and variance\n",
        "\n",
        "        # Decode samples\n",
        "        z_samples_flat = z_samples.view(-1, z_samples.size(-1)) # Flatten out the z samples\n",
        "        x_mean_flat = vae.decode(z_samples_flat) # Push it through\n",
        "\n",
        "        # Reshape images and posterior to evaluate probabilities\n",
        "        x_flat = x[:, None].repeat(1, K, 1, 1, 1).reshape(M*K, -1)\n",
        "        z_mean_flat = z_mean[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n",
        "        z_logvar_flat =  z_logvar[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n",
        "        ZEROS = torch.zeros(z_mean_flat.size())\n",
        "\n",
        "        # Calculate all the probabilities!\n",
        "        log_p_x_z = log_likelihood_bernoulli(torch.sigmoid(x_mean_flat), x_flat).view(M, K)\n",
        "        log_q_z_x = log_likelihood_normal(z_mean_flat, z_logvar_flat, z_samples_flat).view(M, K)\n",
        "        log_p_z = log_likelihood_normal(ZEROS, ZEROS, z_samples_flat).view(M, K)\n",
        "\n",
        "        # Recombine them.\n",
        "        w = log_p_x_z + log_p_z - log_q_z_x\n",
        "        log_p = log_mean_exp(w)\n",
        "\n",
        "        # Accumulate\n",
        "        total_loss += log_p.sum()\n",
        "        total_count += M\n",
        "      \n",
        "print('log p(x):', (total_loss / total_count).item())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "vae_template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
