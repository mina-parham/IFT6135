{"cells":[{"cell_type":"markdown","metadata":{"id":"uTv0D26B9W2h"},"source":["# Assignment 2"]},{"cell_type":"markdown","metadata":{"id":"O9VX-OHxC1FM"},"source":["## Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"qFHMMDtSwuW4"},"outputs":[],"source":["#@title Mount your Google Drive\n","# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n","# you can delete this cell which is specific to Google Colab. You may also\n","# change the paths for data/logs in Arguments below.\n","%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"oODLwt1QzgGa"},"outputs":[],"source":["#@title Link your assignment folder & install requirements\n","#@markdown Enter the path to the assignment folder in your Google Drive\n","# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n","# you can delete this cell which is specific to Google Colab. You may also\n","# change the paths for data/logs in Arguments below.\n","import sys\n","import os\n","import shutil\n","import warnings\n","\n","folder = \"\" #@param {type:\"string\"}\n","!ln -Ts \"$folder\" /content/assignment 2> /dev/null\n","\n","# Add the assignment folder to Python path\n","if '/content/assignment' not in sys.path:\n","  sys.path.insert(0, '/content/assignment')\n","\n","# Install requirements\n","!pip install -qr /content/assignment/requirements.txt\n","\n","# Check if CUDA is available\n","import torch\n","if not torch.cuda.is_available():\n","  warnings.warn('CUDA is not available.')"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"dt3NTvpsy4Oc"},"source":["### Running on GPU\n","For this assignment, it will be necessary to run your experiments on GPU. To make sure the notebook is running on GPU, you can change the notebook settings with\n","* (EN) `Edit > Notebook Settings`\n","* (FR) `Modifier > ParamÃ¨tres du notebook`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLVSmv9HoMH5"},"outputs":[],"source":["%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.optim as optim\n","import urllib.request\n","\n","from dataclasses import dataclass\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","from lstm_solution import LSTM\n","from utils.wikitext2 import Wikitext2\n","from utils.torch_utils import seed_experiment, to_device\n","from utils.data_utils import save_logs\n","from run_exp_lstm import train, evaluate\n"]},{"cell_type":"markdown","metadata":{"id":"-PtvL_yKp3PW"},"source":["## Experiments"]},{"cell_type":"markdown","metadata":{"id":"iWiJme7XaLiR"},"source":["Below we define a few default arguments to get you started with your experiments. You are encouraged to modify the function `main()`, as well as these arguments, to fit your needs (e.g. changing hyperparameters, the optimizer, adding regularization, adding logs)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YUrqebfCobD1"},"outputs":[],"source":["@dataclass\n","class Arguments:\n","  # Data\n","  data_folder: str = '/content/assignment/data'\n","  batch_size: int = 16\n","\n","  # Model\n","  model: str = 'lstm'  # [lstm, gpt1]\n","  embeddings: str = '/content/assignment/data/embeddings.npz'\n","  layers: int = 1\n","\n","  # Optimization\n","  optimizer: str = 'adamw'  # [sgd, momentum, adam, adamw]\n","  epochs: int = 10\n","  lr: float = 1e-3\n","  momentum: float = 0.9\n","  weight_decay: float = 5e-4\n","\n","  # Experiment\n","  exp_id: str = 'debug'\n","  log: bool = True\n","  log_dir: str = '/content/assignment/logs'\n","  seed: int = 42\n","\n","  # Miscellaneous\n","  num_workers: int = 2\n","  device: str = 'cuda'\n","  progress_bar: bool = False\n","  print_every: int = 10"]},{"cell_type":"markdown","metadata":{"id":"5ntfY6yyad_F"},"source":["The 6 configurations you need to run in Problem 1. Be careful that there is no discrepency between the configurations defined in `run_exp_lstm.py` and the ones below. In case there is a difference, the version from `run_exp_lstm.py` should be considered the ones to run."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-q6AwUVDX78-"},"outputs":[],"source":["# Note: if there is any discrepency with the configurations in run_exp_lstm.py, the\n","# version from run_exp_lstm.py should be the ones to use in Problem 1.\n","configs = {\n","  1: Arguments(model='lstm', layers=1, batch_size=16, log=True, epochs=10, optimizer='adam'),\n","  2: Arguments(model='lstm', layers=1, batch_size=16, log=True, epochs=10, optimizer='adamw'),\n","  3: Arguments(model='lstm', layers=1, batch_size=16, log=True, epochs=10, optimizer='sgd'),\n","  4: Arguments(model='lstm', layers=1, batch_size=16, log=True, epochs=10, optimizer='momentum'),\n","\n","  5: Arguments(model='lstm', layers=2, batch_size=16, log=True, epochs=10, optimizer='adamw'),\n","  6: Arguments(model='lstm', layers=4, batch_size=16, log=True, epochs=10, optimizer='adamw')\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2rjoY-5phTY"},"outputs":[],"source":["def main(args):\n","  # Seed the experiment, for repeatability\n","  seed_experiment(args.seed)\n","\n","  # Dataloaders\n","  train_dataset = Wikitext2(args.data_folder, split=\"train\")\n","  train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=args.batch_size,\n","    shuffle=True,\n","    num_workers=args.num_workers,\n","  )\n","\n","  valid_dataset = Wikitext2(args.data_folder, split=\"validation\")\n","  valid_dataloader = DataLoader(\n","    valid_dataset,\n","    batch_size=args.batch_size,\n","    shuffle=False,\n","    num_workers=args.num_workers,\n","  )\n","\n","  test_dataset = Wikitext2(args.data_folder, split=\"test\")\n","  test_dataloader = DataLoader(\n","    test_dataset,\n","    batch_size=args.batch_size,\n","    shuffle=False,\n","    num_workers=args.num_workers,\n","  )\n","\n","  # Download the embeddings\n","  if not os.path.isfile(args.embeddings):\n","    print(\"No embedding file please place embedding.pkl in ./data\")\n","\n","  # Model\n","  if args.model == \"lstm\":\n","    model = LSTM.load_embeddings_from(\n","      args.embeddings, hidden_size=512, num_layers=args.layers\n","    )\n","  else:\n","    raise ValueError(\"Unknown model {0}\".format(args.model))\n","  model.to(args.device)\n","\n","  # Optimizer\n","  if args.optimizer == \"adamw\":\n","    optimizer = optim.AdamW(\n","      model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n","    )\n","  elif args.optimizer == \"adam\":\n","    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","  elif args.optimizer == \"sgd\":\n","    optimizer = optim.SGD(\n","      model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n","    )\n","  elif args.optimizer == \"momentum\":\n","    optimizer = optim.SGD(\n","      model.parameters(),\n","      lr=args.lr,\n","      momentum=args.momentum,\n","      weight_decay=args.weight_decay,\n","    )\n","\n","  print(\n","    f\"Initialized {args.model.upper()} model with {sum(p.numel() for p in model.parameters())} \"\n","    f\"total parameters, of which {sum(p.numel() for p in model.parameters() if p.requires_grad)} are learnable.\"\n","  )\n","\n","  train_losses, valid_losses = [], []\n","  train_ppls, valid_ppls = [], []\n","  train_times, valid_times = [], []\n","  for epoch in range(args.epochs):\n","\n","    tqdm.write(f\"====== Epoch {epoch} ======>\")\n","\n","    loss, ppl, wall_time = train(epoch, model, train_dataloader, optimizer, args)\n","    train_losses.append(loss)\n","    train_ppls.append(ppl)\n","    train_times.append(wall_time)\n","\n","    loss, ppl, wall_time = evaluate(epoch, model, valid_dataloader, args)\n","    valid_losses.append(loss)\n","    valid_ppls.append(ppl)\n","    valid_times.append(wall_time)\n","\n","  test_loss, test_ppl, test_time = evaluate(\n","    epoch, model, test_dataloader, args, mode=\"test\"\n","  )\n","\n","  print(f\"===== Best validation perplexity: {min(valid_ppls):.3f} =====>\")\n","\n","  return (\n","    train_losses,\n","    train_ppls,\n","    train_times,\n","    valid_losses,\n","    valid_ppls,\n","    valid_times,\n","    test_loss,\n","    test_ppl,\n","    test_time,\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyJPWO1ppcTx"},"outputs":[],"source":["args = configs[1]  # Run the first configuration\n","logs = main(args)\n","if args.log:\n","  save_logs(args, *logs)"]},{"cell_type":"markdown","metadata":{},"source":["Similarly you can add and run the configs listed in 'run_exps_vit.py' for the problem 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwWZq6zk0YDF"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"main.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"nbformat":4,"nbformat_minor":0}
